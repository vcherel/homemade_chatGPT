"""
A function used to clean the tokens generated by the NLTK tokenizer.
We remove some tokens that are not useful for the model.
"""
def clean_utterance(buf: list[str]) -> list[str]:
    '''
    Clean the input list of tokens, killing mostly punctuations and horrors that remains from tokenization.
    '''
    
    ignore = ("``", "''", "(", ")", '<', 'br', '/', '>', '--', '*', '-')
    
    return [x.lower() for x in buf if x.lower() not in ignore]


